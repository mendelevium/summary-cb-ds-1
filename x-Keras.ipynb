{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3-final"},"colab":{"name":"Math Functions.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5Yiopyo2Ihhk","colab_type":"text"},"source":["# Keras\n","[Examples](https://keras.io/examples/)\n","\n","```pip install tensorflow```"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn.datasets import load_iris"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["iris = load_iris()\n","#print(iris.DESCR)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["X = iris.data\n","y = iris.target"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# encode target to one-hot\n","from keras.utils import to_categorical\n","y = to_categorical(y)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# Split test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Preprocessing\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_object = MinMaxScaler()\n","scaler_object.fit(X_train)\n","scaled_X_train = scaler_object.transform(X_train)\n","scaled_X_test = scaler_object.transform(X_test)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 8)                 40        \n_________________________________________________________________\ndense_1 (Dense)              (None, 8)                 72        \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 27        \n=================================================================\nTotal params: 139\nTrainable params: 139\nNon-trainable params: 0\n_________________________________________________________________\n"]}],"source":["# Building Network \n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","model = Sequential()\n","model.add(Dense(8, input_dim=4, activation='relu')) # Input layer\n","model.add(Dense(8, input_dim=4, activation='relu')) # Hidden layer\n","model.add(Dense(3, activation='softmax')) # Output layer\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8200\n","Epoch 2/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8400\n","Epoch 3/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8500\n","Epoch 4/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8200\n","Epoch 5/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8100\n","Epoch 6/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7900\n","Epoch 7/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7600\n","Epoch 8/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7400\n","Epoch 9/200\n","4/4 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7400\n","Epoch 10/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7400\n","Epoch 11/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.7600\n","Epoch 12/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7900\n","Epoch 13/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8400\n","Epoch 14/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8400\n","Epoch 15/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8500\n","Epoch 16/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8500\n","Epoch 17/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8800\n","Epoch 18/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8800\n","Epoch 19/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8900\n","Epoch 20/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8800\n","Epoch 21/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8800\n","Epoch 22/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8800\n","Epoch 23/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8700\n","Epoch 24/200\n","4/4 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8700\n","Epoch 25/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8600\n","Epoch 26/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8700\n","Epoch 27/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8800\n","Epoch 28/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8800\n","Epoch 29/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8900\n","Epoch 30/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8800\n","Epoch 31/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8800\n","Epoch 32/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8800\n","Epoch 33/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8800\n","Epoch 34/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8800\n","Epoch 35/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8800\n","Epoch 36/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8800\n","Epoch 37/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8900\n","Epoch 38/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8900\n","Epoch 39/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8900\n","Epoch 40/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8900\n","Epoch 41/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8900\n","Epoch 42/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8800\n","Epoch 43/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8800\n","Epoch 44/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8800\n","Epoch 45/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8800\n","Epoch 46/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8800\n","Epoch 47/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8800\n","Epoch 48/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8800\n","Epoch 49/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8800\n","Epoch 50/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8900\n","Epoch 51/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8900\n","Epoch 52/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8900\n","Epoch 53/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8800\n","Epoch 54/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8800\n","Epoch 55/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8900\n","Epoch 56/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8900\n","Epoch 57/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.9000\n","Epoch 58/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.9300\n","Epoch 59/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.9400\n","Epoch 60/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.9400\n","Epoch 61/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.9300\n","Epoch 62/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.9300\n","Epoch 63/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.9200\n","Epoch 64/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.9100\n","Epoch 65/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.9200\n","Epoch 66/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.9000\n","Epoch 67/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.9300\n","Epoch 68/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.9300\n","Epoch 69/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.9500\n","Epoch 70/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.9500\n","Epoch 71/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.9500\n","Epoch 72/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.9500\n","Epoch 73/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.9500\n","Epoch 74/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.9500\n","Epoch 75/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.9500\n","Epoch 76/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.9500\n","Epoch 77/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.9500\n","Epoch 78/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.9500\n","Epoch 79/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9500\n","Epoch 80/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.9500\n","Epoch 81/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.9500\n","Epoch 82/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9500\n","Epoch 83/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.9500\n","Epoch 84/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.9500\n","Epoch 85/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9500\n","Epoch 86/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.2699 - accuracy: 0.9500\n","Epoch 87/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.9500\n","Epoch 88/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.9500\n","Epoch 89/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.9600\n","Epoch 90/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.9600\n","Epoch 91/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.9500\n","Epoch 92/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.9500\n","Epoch 93/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9500\n","Epoch 94/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9500\n","Epoch 95/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9500\n","Epoch 96/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9500\n","Epoch 97/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9500\n","Epoch 98/200\n","4/4 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9500\n","Epoch 99/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9500\n","Epoch 100/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.9500\n","Epoch 101/200\n","4/4 [==============================] - 0s 9ms/step - loss: 0.2321 - accuracy: 0.9600\n","Epoch 102/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2291 - accuracy: 0.9500\n","Epoch 103/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9500\n","Epoch 104/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9500\n","Epoch 105/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9500\n","Epoch 106/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9500\n","Epoch 107/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9500\n","Epoch 108/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9500\n","Epoch 109/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2148 - accuracy: 0.9500\n","Epoch 110/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9600\n","Epoch 111/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2153 - accuracy: 0.9600\n","Epoch 112/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9500\n","Epoch 113/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9600\n","Epoch 114/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9600\n","Epoch 115/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9500\n","Epoch 116/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9500\n","Epoch 117/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9500\n","Epoch 118/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1992 - accuracy: 0.9500\n","Epoch 119/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9500\n","Epoch 120/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9500\n","Epoch 121/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9500\n","Epoch 122/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9500\n","Epoch 123/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1921 - accuracy: 0.9500\n","Epoch 124/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9500\n","Epoch 125/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9500\n","Epoch 126/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9500\n","Epoch 127/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9500\n","Epoch 128/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9500\n","Epoch 129/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.9500\n","Epoch 130/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1814 - accuracy: 0.9500\n","Epoch 131/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1795 - accuracy: 0.9500\n","Epoch 132/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9500\n","Epoch 133/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9500\n","Epoch 134/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9500\n","Epoch 135/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9700\n","Epoch 136/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9700\n","Epoch 137/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9700\n","Epoch 138/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.9700\n","Epoch 139/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9500\n","Epoch 140/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9500\n","Epoch 141/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1664 - accuracy: 0.9500\n","Epoch 142/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1655 - accuracy: 0.9500\n","Epoch 143/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9500\n","Epoch 144/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9500\n","Epoch 145/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9600\n","Epoch 146/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9600\n","Epoch 147/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1620 - accuracy: 0.9700\n","Epoch 148/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.9700\n","Epoch 149/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.9700\n","Epoch 150/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.9600\n","Epoch 151/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.9600\n","Epoch 152/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.9500\n","Epoch 153/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9600\n","Epoch 154/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9600\n","Epoch 155/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9600\n","Epoch 156/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9600\n","Epoch 157/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9600\n","Epoch 158/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9600\n","Epoch 159/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9500\n","Epoch 160/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9600\n","Epoch 161/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9600\n","Epoch 162/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9600\n","Epoch 163/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9700\n","Epoch 164/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.9700\n","Epoch 165/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9700\n","Epoch 166/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9600\n","Epoch 167/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9600\n","Epoch 168/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9600\n","Epoch 169/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9600\n","Epoch 170/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9600\n","Epoch 171/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9700\n","Epoch 172/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9600\n","Epoch 173/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1369 - accuracy: 0.9600\n","Epoch 174/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9600\n","Epoch 175/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9600\n","Epoch 176/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9600\n","Epoch 177/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9600\n","Epoch 178/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9600\n","Epoch 179/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9600\n","Epoch 180/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9600\n","Epoch 181/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9600\n","Epoch 182/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9600\n","Epoch 183/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.9600\n","Epoch 184/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9600\n","Epoch 185/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9700\n","Epoch 186/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9600\n","Epoch 187/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1270 - accuracy: 0.9600\n","Epoch 188/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9700\n","Epoch 189/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9700\n","Epoch 190/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9700\n","Epoch 191/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9700\n","Epoch 192/200\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9600\n","Epoch 193/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.9600\n","Epoch 194/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9600\n","Epoch 195/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9700\n","Epoch 196/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1228 - accuracy: 0.9700\n","Epoch 197/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9700\n","Epoch 198/200\n","4/4 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9700\n","Epoch 199/200\n","4/4 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9600\n","Epoch 200/200\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.9600\n"]}],"source":["# Train and Predict\n","model.fit(scaled_X_train,y_train,epochs=200, verbose=1)\n","\n","# Spits out probabilities by default.\n","# predictions = model.predict(scaled_X_test)\n","predictions = model.predict_classes(scaled_X_test)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["[[19  0  0]\n [ 0 14  1]\n [ 0  0 16]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        19\n           1       1.00      0.93      0.97        15\n           2       0.94      1.00      0.97        16\n\n    accuracy                           0.98        50\n   macro avg       0.98      0.98      0.98        50\nweighted avg       0.98      0.98      0.98        50\n\n"]}],"source":["# Evaluate\n","from sklearn import metrics\n","# .argmax(axis=1) transform one-hot back to category \n","print(metrics.confusion_matrix(y_test.argmax(axis=1),predictions))\n","print(metrics.classification_report(y_test.argmax(axis=1),predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save\n","model.save('myfirstmodel.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load\n","from keras.models import load_model\n","newmodel = load_model('myfirstmodel.h5')\n","newmodel.predict_classes(scaled_X_test)"]},{"source":["## Learning curves\n","\n","**error (dev set, train set) vs m (training set size)** : tells if more data is needed to reach acceptable level of error\n","\n","\n"],"cell_type":"markdown","metadata":{}},{"source":["### Reducing Bias\n","- Increase the model size\n","- Add features aim at the bias\n","- Reduce regularization\n","- Modify model architecture\n","\n","### Reducing variance\n","- Add more data\n","- Add regularization\n","- Early stopping (decrease tolerance)\n","- Feature selection (reduction)\n","- Decrease model size"],"cell_type":"markdown","metadata":{}}]}