{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "We've been on the user (or query) side of APIs before, now we're going to be on the server side.\n",
    "\n",
    "The simplest and most popular python framework for serving an API is [Flask](https://flask.palletsprojects.com/en/1.1.x/quickstart/)\n",
    "\n",
    "The file `m6a_flask_example.py` has a minimal \"Hello World\" flask app.\n",
    "\n",
    "You can start it by running it from the command line `python m6b_flask_example.py`\n",
    "\n",
    "Then go to your browser to `http://0.0.0.0:5000/` and you'll see `Hello World` being printed. Similarly if we do a `GET` request in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'Hello, World!'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://0.0.0.0:5000/')\n",
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we kill the server, this stops working.\n",
    "\n",
    "Here's a second example of a slightly more complex server setup emulating a machine learning app.\n",
    "\n",
    "It has a `GET` which returns the expected input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n        Expected JSON input:\n        {\n            \"age\" : NUMBER\n            \"income\" : NUMBER\n        }\n        \n"
    }
   ],
   "source": [
    "r = requests.get('http://0.0.0.0:5000/')\n",
    "# Output is raw bytes\n",
    "print(r.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has a `POST` method which takes in a JSON to do model inference on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'{\"result\": -137874}'"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "query = json.dumps({\n",
    "    \"age\": 42,\n",
    "    \"income\": 69_000,\n",
    "})\n",
    "\n",
    "# Note that since we're picking up the `data` parameter on server side\n",
    "# We send it through the data parameter on client side, too.\n",
    "r = requests.post('http://0.0.0.0:5000/', data=query)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}